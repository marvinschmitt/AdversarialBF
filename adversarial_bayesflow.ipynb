{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Adversarial BayesFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../BayesFlow')))\n",
    "\n",
    "from bayesflow.trainers import ParameterEstimationTrainer\n",
    "from bayesflow.networks import InvertibleNetwork, InvariantNetwork\n",
    "from bayesflow.amortizers import SingleModelAmortizer\n",
    "from bayesflow.models import GenerativeModel\n",
    "from bayesflow.diagnostics import true_vs_estimated\n",
    "from bayesflow.exceptions import ConfigurationError\n",
    "\n",
    "from bayesflow.applications.priors import GaussianMeanPrior, TPrior, GaussianMeanCovPrior\n",
    "from bayesflow.applications.simulators import GaussianMeanSimulator, MultivariateTSimulator, GaussianMeanCovSimulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) MVN means\n",
    "**Task:** Learn means of a 5-variate Gaussian with unit variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define minimalistic BayesFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "\n",
    "#########\n",
    "\n",
    "prior = GaussianMeanPrior(D=D)\n",
    "simulator = GaussianMeanSimulator(D=D)\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "\n",
    "#########\n",
    "\n",
    "summary_meta = {\n",
    "    'n_dense_s1': 2,\n",
    "    'n_dense_s2': 2,\n",
    "    'n_dense_s3': 2,\n",
    "    'n_equiv':    1,\n",
    "    'dense_s1_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s2_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s3_args': {'activation': 'relu', 'units': 32},\n",
    "}\n",
    "\n",
    "class BottleneckSummaryNet(tf.keras.Model):\n",
    "    def __init__(self, inv_meta={}, n_out=10, activation_out=None):\n",
    "        super(BottleneckSummaryNet, self).__init__()\n",
    "\n",
    "        self.invariant_net = InvariantNetwork(inv_meta)\n",
    "        self.out_layer = tf.keras.layers.Dense(n_out, activation=activation_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out_inv = self.invariant_net(x)\n",
    "        out = self.out_layer(out_inv)\n",
    "        return out\n",
    "\n",
    "\n",
    "summary_net = BottleneckSummaryNet(inv_meta=summary_meta, \n",
    "                                   n_out=D*2,  # one mean and variance per dim\n",
    "                                   activation_out=None  # linear\n",
    "                                  )\n",
    "\n",
    "\n",
    "inference_meta = {\n",
    "    'n_coupling_layers': 2,\n",
    "    's_args': {\n",
    "        'units': [32, 32, 32],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [32, 32, 32],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'n_params': D,\n",
    "    'alpha': 1.9,\n",
    "    'permute': True\n",
    "}\n",
    "\n",
    "inference_net = InvertibleNetwork(inference_meta)\n",
    "\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ParameterEstimationTrainer(amortizer,\n",
    "                      generative_model,\n",
    "                      learning_rate=0.0001,\n",
    "                      checkpoint_path='export_ckpt/stefan/mean_5D',\n",
    "                      max_to_keep = 2\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converge BayesFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = trainer.train_rounds(epochs=2, rounds=2, sim_per_round=20000, batch_size=1024, n_obs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate (quick and dirty)\n",
    "p, x = trainer._forward_inference(200, 100)\n",
    "param_samples = trainer.network.sample(x, n_samples=200)\n",
    "param_means = param_samples.mean(axis=0)\n",
    "true_vs_estimated(p, param_means, ['mu{}'.format(i) for i in range(1, 5+1)], figsize=(20,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array(trainer.network.summary_net(x))\n",
    "sns.pairplot(pd.DataFrame(s, columns=['s_{}'.format(i) for i in range(1, s.shape[1]+1)]), kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypersetup for all tasks\n",
    "D = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_analytic_posterior(prior, simulator, x):\n",
    "    n_sim, n_obs, D = x.shape\n",
    "    \n",
    "    # Set up variables\n",
    "    x_bar = np.mean(x, axis=1)                 # empirical mean\n",
    "    sigma_0 = np.eye(D) * prior.mu_scale       # mu prior covariance\n",
    "    sigma_0_inv = np.linalg.inv(sigma_0)       # inverse mu prior covariance\n",
    "    mu_0 = np.ones((D, 1)) * prior.mu_mean     # mu prior mean\n",
    "    sigma = simulator.sigma                    # likelihood covariance\n",
    "    sigma_inv = np.linalg.inv(sigma)           # inverse likelihood covariance\n",
    "    \n",
    "    mu_posterior_covariance = np.stack([np.linalg.inv(sigma_0_inv + n_obs*sigma_inv)] * n_sim)\n",
    "    \n",
    "    mu_posterior_mean = mu_posterior_covariance @ (sigma_0_inv @ mu_0 + n_obs * (sigma_inv @ x_bar[..., np.newaxis]))   \n",
    "    mu_posterior_mean = mu_posterior_mean.reshape(n_sim, D)\n",
    "\n",
    "    return mu_posterior_mean, mu_posterior_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_diagnostics(trainer, generative_model, theta=None, x=None, print_pairplot_summarynet=False, print_pairplot_posteriors=False):\n",
    "    theta, x = generative_model(200, 100) if theta is None and x is None else (theta, x)\n",
    "    param_samples = trainer.network.sample(x, n_samples=200)\n",
    "    param_means = param_samples.mean(axis=0)\n",
    "    \n",
    "    # true parameters\n",
    "    print(\"BayesFlow (x) vs. true thetas (y) -- Recovery of true thetas\")\n",
    "    true_vs_estimated(theta, param_means, ['mu{}'.format(i) for i in range(1, 5+1)], figsize=(20,4))\n",
    "    \n",
    "    # analytic posteriors\n",
    "    print(\"\\n\\nBayesFlow (x) vs. analytic posterior means (y) -- Recovery of analytic posterior means\")\n",
    "    prior = trainer.generative_model.prior.__self__\n",
    "    simulator = trainer.generative_model.simulator\n",
    "    posterior_means, posterior_covariances = calculate_analytic_posterior(prior, simulator, x)\n",
    "    posterior_variances = posterior_covariances.diagonal(axis1=1, axis2=2)\n",
    "    true_vs_estimated(posterior_means, param_means, ['mu{}'.format(i) for i in range(1, 5+1)], figsize=(20,4))\n",
    "    \n",
    "    print(\"\\n\\nAnalytic posterior means (x) vs. true thetas (y)\")\n",
    "    true_vs_estimated(posterior_means, theta, ['mu{}'.format(i) for i in range(1, 5+1)], figsize=(20,4))\n",
    "\n",
    "    if print_pairplot_summarynet:\n",
    "        print('\\n\\nSummary network response for one batch')\n",
    "        s = np.array(trainer.network.summary_net(x))\n",
    "        sns.pairplot(pd.DataFrame(s, columns=['s_{}'.format(i) for i in range(1, s.shape[1]+1)]), kind=\"kde\")\n",
    "        \n",
    "    if print_pairplot_posteriors:\n",
    "        print('\\n\\nFull posterior for one dataset.')\n",
    "        p = param_samples[0]\n",
    "        sns.pairplot(pd.DataFrame(p, columns=['dim_{}'.format(i) for i in range(1, p.shape[1]+1)]), kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A1) Wrong Prior\n",
    "The prior over the multivariate Gaussian's means is Gaussian: $\\mu\\sim\\mathcal{N}(\\mu_\\mu, \\sigma_\\mu)$\n",
    "\n",
    "During training, the mean's prior was $\\mu\\sim\\mathcal{N}(0, 1)$. This adversarial tasks varies the prior in three steps for the evaluation:\n",
    "\n",
    "- **(A1)-1** Wrong (free) prior location: $\\mu\\sim\\mathcal{N}(\\mu_\\mu, 1)$\n",
    "- **(A1)-2** Wrong (free) prior scale: $\\mu\\sim\\mathcal{N}(0, \\sigma_\\mu)$\n",
    "- **(A1)-3** Wrong (free) prior location and scale: $\\mu\\sim\\mathcal{N}(\\mu_\\mu, \\sigma_\\mu)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A1)-1 Wrong prior location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior wrong, model misspecified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prior = GaussianMeanPrior(D=D, mu_mean=5, mu_scale=1)\n",
    "simulator = GaussianMeanSimulator(D=D)\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "\n",
    "adversarial_diagnostics(trainer, generative_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A1)-2 Wrong prior scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prior = GaussianMeanPrior(D=D, mu_mean=0, mu_scale=5)\n",
    "simulator = GaussianMeanSimulator(D=D)\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "\n",
    "adversarial_diagnostics(trainer, generative_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A1)-3 Wrong prior location and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prior = GaussianMeanPrior(D=D, mu_mean=5, mu_scale=5)\n",
    "simulator = GaussianMeanSimulator(D=D)\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "\n",
    "adversarial_diagnostics(trainer, generative_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A2) Wrong Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = GaussianMeanPrior(D=D, mu_mean=0, mu_scale=1)\n",
    "simulator = GaussianMeanSimulator(D=D, s = 5.0)\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "\n",
    "adversarial_diagnostics(trainer, generative_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = GaussianMeanPrior(D=D, mu_mean=0, mu_scale=1)\n",
    "simulator = GaussianMeanSimulator(D=D, s = [1, 1, 10, 5, 3])\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "\n",
    "adversarial_diagnostics(trainer, generative_model, print_pairplot_summarynet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = GaussianMeanPrior(D=D, mu_mean=0, mu_scale=1)\n",
    "simulator = MultivariateTSimulator(df=2)\n",
    "\n",
    "means = prior(200)\n",
    "sigma = np.ones_like(means)\n",
    "theta = np.concatenate((means, sigma), axis=1)\n",
    "x = simulator(theta, 100)\n",
    "\n",
    "\n",
    "adversarial_diagnostics(trainer, generative_model=None, theta=theta, x=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A4) Contamination\n",
    "$\\mathbf{x}_n = \\mathbf{x}_n + \\xi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    n_sim, n_obs, data_dim = x.shape\n",
    "    s = np.std(x, axis=1)\n",
    "    s_reshaped = s.reshape(n_sim, 1, data_dim).repeat(n_obs, axis=1)\n",
    "    x_normalized = np.divide(x, s_reshaped)\n",
    "    return x_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pink noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, the contamination $\\xi$ is *pink noise* (aka $\\frac{1}{f}$ noise) and added to the data $x$. The contaminated data is then normalized to obtain unit variance again.\n",
    "\n",
    "$\\tilde{x}=\\dfrac{x+\\xi}{\\sigma_{x+\\xi}}$ with $\\xi \\sim \\frac{1}{f}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior correct, model misspecified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorednoise as cn\n",
    "\n",
    "prior = GaussianMeanPrior(D=D, mu_mean=0, mu_scale=1)\n",
    "simulator = GaussianMeanSimulator(D=D)\n",
    "\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "theta, x = generative_model(200, 100)\n",
    "\n",
    "lamda = 1.0  # contribution of contamination xi \n",
    "\n",
    "xi = cn.powerlaw_psd_gaussian(exponent=1, size=x.shape)\n",
    "\n",
    "x_tilde = normalize(x + lamda * xi)\n",
    "\n",
    "adversarial_diagnostics(trainer, generative_model=None, theta=theta, x=x_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t Noise\n",
    "In this scenario, the contamination $\\xi$ is $t-$distributed and added to the data $x$. The contaminated data is then normalized to obtain unit variance again.\n",
    "\n",
    "$\\tilde{x}=\\dfrac{x+\\xi}{\\sigma_{x+\\xi}}$ with $\\xi \\sim t(2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = GaussianMeanPrior(D=D, mu_mean=0, mu_scale=1)\n",
    "simulator = GaussianMeanSimulator(D=D)\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "\n",
    "theta, x = generative_model(200, 100)\n",
    "\n",
    "n_sim, n_obs, data_dim = x.shape\n",
    "\n",
    "\n",
    "lamda = 0.5\n",
    "xi_theta = np.concatenate((np.zeros((n_sim, data_dim)), np.ones((n_sim, data_dim))), axis=1)\n",
    "xi_simulator = MultivariateTSimulator(df=2)\n",
    "xi = xi_simulator(xi_theta, n_obs)\n",
    "\n",
    "x_tilde = normalize(x + lamda * xi)\n",
    "\n",
    "adversarial_diagnostics(trainer, generative_model=None, theta=theta, x=x_tilde, print_pairplot_posteriors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) MVN means and variances (diagonal covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiagCovPrior:\n",
    "    def __init__(self, D, alpha_0=5.0, beta_0=5.0, lamda_0=1.0, mu_0_mean=0.0, mu_0_scale=1.0):\n",
    "        self.D = D\n",
    "        \n",
    "        assert isinstance(alpha_0, (int, float, list, np.ndarray))\n",
    "        if not isinstance(alpha_0, (list, np.ndarray)):\n",
    "            alpha_0 = [alpha_0] * self.D\n",
    "        else:\n",
    "            assert len(alpha_0) == self.D\n",
    "        alpha_0 = np.array(alpha_0, dtype=np.float)\n",
    "        \n",
    "        assert isinstance(beta_0, (int, float, list, np.ndarray))\n",
    "        if not isinstance(beta_0, (list, np.ndarray)):\n",
    "            beta_0 = [beta_0] * self.D\n",
    "        else:\n",
    "            assert len(beta_0) == self.D\n",
    "        beta_0 = np.array(beta_0, dtype=np.float)\n",
    "        \n",
    "        \n",
    "        self.alpha_0 = alpha_0\n",
    "        self.beta_0 = beta_0\n",
    "        self.lamda_0 = lamda_0\n",
    "\n",
    "        assert isinstance(self.alpha_0, np.ndarray)\n",
    "        assert isinstance(self.beta_0, np.ndarray)\n",
    "        \n",
    "        assert isinstance(mu_0_mean, (float, int))\n",
    "        assert isinstance(mu_0_scale, (float, int))\n",
    "        self.mu_0_mean = mu_0_mean\n",
    "        self.mu_0_scale = mu_0_scale\n",
    "        \n",
    "        \n",
    "        self.inv_gammas = tfp.distributions.InverseGamma(self.alpha_0, self.beta_0).sample\n",
    "        self.mu_prior = GaussianMeanPrior(self.D, mu_mean=mu_0_mean, mu_scale=mu_0_scale)\n",
    "        \n",
    "        \n",
    "\n",
    "    def __call__(self, n_sim):\n",
    "        cov = np.zeros((n_sim, self.D, self.D))\n",
    "        diag = self.inv_gammas(n_sim)\n",
    "        \n",
    "        # optimize me please\n",
    "        for i in range(cov.shape[0]):\n",
    "            np.fill_diagonal(cov[i], diag[i])\n",
    "            \n",
    "        cov = cov / self.lamda_0\n",
    "        mu = self.mu_prior(n_sim)\n",
    "        return mu, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "\n",
    "#########\n",
    "\n",
    "def param_transform_diag_cov(theta):\n",
    "    means, cov = theta\n",
    "    means = np.array(means)\n",
    "    cov = np.array(cov)\n",
    "    cov = np.diagonal(cov, axis1=1, axis2=2)\n",
    "    return np.concatenate([means, cov], axis=1)\n",
    "\n",
    "prior = GaussianDiagCovPrior(D=D)\n",
    "simulator = GaussianMeanCovSimulator()\n",
    "generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_diag_cov)\n",
    "\n",
    "#########\n",
    "\n",
    "summary_meta = {\n",
    "    'n_dense_s1': 2,\n",
    "    'n_dense_s2': 2,\n",
    "    'n_dense_s3': 2,\n",
    "    'n_equiv':    2,\n",
    "    'dense_s1_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s2_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s3_args': {'activation': 'relu', 'units': 32},\n",
    "}\n",
    "\n",
    "class BottleneckSummaryNet(tf.keras.Model):\n",
    "    def __init__(self, inv_meta={}, n_out=10, activation_out=None):\n",
    "        super(BottleneckSummaryNet, self).__init__()\n",
    "\n",
    "        self.invariant_net = InvariantNetwork(inv_meta)\n",
    "        self.out_layer = tf.keras.layers.Dense(n_out, activation=activation_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out_inv = self.invariant_net(x)\n",
    "        out = self.out_layer(out_inv)\n",
    "        return out\n",
    "\n",
    "\n",
    "summary_net = BottleneckSummaryNet(inv_meta=summary_meta, \n",
    "                                   n_out=2*2*D,   # twice the required\n",
    "                                   activation_out=None  # linear\n",
    ")\n",
    "\n",
    "\n",
    "inference_meta = {\n",
    "    'n_coupling_layers': 2,\n",
    "    's_args': {\n",
    "        'units': [64, 64, 64],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [64, 64, 64],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'n_params': 2*D,\n",
    "    'alpha': 1.9,\n",
    "    'permute': True\n",
    "}\n",
    "\n",
    "inference_net = InvertibleNetwork(inference_meta)\n",
    "\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)\n",
    "\n",
    "trainer = ParameterEstimationTrainer(amortizer,\n",
    "                      generative_model,\n",
    "                      learning_rate=0.0001,\n",
    "                      checkpoint_path='export_ckpt/stefan/diag_cov_5D',\n",
    "                      max_to_keep = 2\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = trainer.train_online(epochs=2, iterations_per_epoch=2, batch_size=1024, n_obs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, x = generative_model(200, 100)\n",
    "param_samples = trainer.network.sample(x, n_samples=200)\n",
    "param_means = param_samples.mean(axis=0)\n",
    "\n",
    "print(\"BayesFlow (x) vs. true thetas (y) -- Recovery of true thetas\")\n",
    "true_vs_estimated(theta, param_means,\n",
    "                  ['mu{}'.format(i) for i in range(1, D+1)]+\n",
    "                  ['var{}'.format(i) for i in range(1, D+1)],\n",
    "                  figsize=(20,8))\n",
    "\n",
    "\n",
    "#print('\\n\\nSummary network response for one batch')\n",
    "#s = np.array(trainer.network.summary_net(x))\n",
    "#sns.pairplot(pd.DataFrame(s, columns=['s_{}'.format(i) for i in range(1, s.shape[1]+1)]), kind=\"kde\")\n",
    "\n",
    "#print('\\n\\nFull posterior for one dataset.')\n",
    "#p = param_samples[0]\n",
    "#sns.pairplot(pd.DataFrame(p, columns=['dim_{}'.format(i) for i in range(1, p.shape[1]+1)]), kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) MVN means and full covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "\n",
    "#########\n",
    "\n",
    "def param_transform_full_cov(theta):\n",
    "    means, cov = theta\n",
    "    means = np.array(means)\n",
    "    n_sim, D = means.shape\n",
    "    cov = np.array(cov)\n",
    "    cov = cov[np.tril(cov).nonzero()].reshape(n_sim, -1)\n",
    "    return np.concatenate([means, cov], axis=1)\n",
    "\n",
    "prior = GaussianMeanCovPrior(D=D, a0=D+1, b0=1, m0=0, beta0=1)\n",
    "simulator = GaussianMeanCovSimulator()\n",
    "generative_model = GenerativeModel(prior, simulator, param_transform=param_transform_full_cov)\n",
    "\n",
    "#########\n",
    "\n",
    "summary_meta = {\n",
    "    'n_dense_s1': 2,\n",
    "    'n_dense_s2': 2,\n",
    "    'n_dense_s3': 2,\n",
    "    'n_equiv':    2,\n",
    "    'dense_s1_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s2_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s3_args': {'activation': 'relu', 'units': 32},\n",
    "}\n",
    "\n",
    "class BottleneckSummaryNet(tf.keras.Model):\n",
    "    def __init__(self, inv_meta={}, n_out=10, activation_out=None):\n",
    "        super(BottleneckSummaryNet, self).__init__()\n",
    "\n",
    "        self.invariant_net = InvariantNetwork(inv_meta)\n",
    "        self.out_layer = tf.keras.layers.Dense(n_out, activation=activation_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out_inv = self.invariant_net(x)\n",
    "        out = self.out_layer(out_inv)\n",
    "        return out\n",
    "\n",
    "\n",
    "summary_net = BottleneckSummaryNet(inv_meta=summary_meta, \n",
    "                                   n_out=(sum(range(1, D+1)) + D) * 2,   # twice the required\n",
    "                                   activation_out=None  # linear\n",
    ")\n",
    "\n",
    "\n",
    "inference_meta = {\n",
    "    'n_coupling_layers': 2,\n",
    "    's_args': {\n",
    "        'units': [64, 64, 64],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [64, 64, 64],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'n_params': sum(range(1, D+1)) + D,   # lower diagonal cov (1+2+...+D) and D means\n",
    "    'alpha': 1.9,\n",
    "    'permute': True\n",
    "}\n",
    "\n",
    "inference_net = InvertibleNetwork(inference_meta)\n",
    "\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)\n",
    "\n",
    "trainer = ParameterEstimationTrainer(amortizer,\n",
    "                      generative_model,\n",
    "                      learning_rate=0.0001,\n",
    "                      checkpoint_path='export_ckpt/stefan/full_cov_5D',\n",
    "                      max_to_keep = 2\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = trainer.train_rounds(epochs=2, rounds=2, sim_per_round=10000, batch_size=1000, n_obs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_list_to_mean_cov(theta, D):\n",
    "    # setup\n",
    "    n_sim = theta.shape[0]\n",
    "    mean = theta[:, :D]\n",
    "    cov_list = theta[:, D:]\n",
    "    tril_idx1, tril_idx2 = np.tril_indices(D)\n",
    "    cov = np.zeros((n_sim, D, D))\n",
    "    \n",
    "    # fill cov matrix\n",
    "    for i in range(n_sim):\n",
    "        # write from flattened array into in lower triangular matrix\n",
    "        cov[i, tril_idx1, tril_idx2] = cov_list[i, :]\n",
    "        \n",
    "        # mirror lower triangular matrix to upper triangle\n",
    "        cov[i] = cov[i] + cov[i].T - np.diag(np.diag(cov[i]))\n",
    "    return mean, cov\n",
    "\n",
    "def cov_to_corr(cov, std_devs_on_diagonal=True, epsilon=1e-6):\n",
    "    corr = np.zeros_like(cov)\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        # extract 2D matrix\n",
    "        Sigma = cov[i, :, :]\n",
    "        \n",
    "        # transform 2D cov matrix into corr matrix\n",
    "        std_devs = np.sqrt(np.maximum(np.diag(Sigma), epsilon))\n",
    "        Dinv = np.diag(1 / std_devs)\n",
    "        corr[i] = Dinv @ Sigma @ Dinv\n",
    "        \n",
    "        # increase information by putting SDs on diagonal instead of 1's\n",
    "        if std_devs_on_diagonal:\n",
    "            np.fill_diagonal(corr[i], std_devs)\n",
    "            \n",
    "    return corr\n",
    "\n",
    "def theta_cov_to_corr(theta, D):\n",
    "    mean, cov = param_list_to_mean_cov(theta, D=D)\n",
    "    corr = cov_to_corr(cov)\n",
    "    theta_corr = param_transform_full_cov((mean, corr))\n",
    "    return theta_corr\n",
    "\n",
    "def true_vs_estimated_tril(theta_true, theta_est, param_names, D, dpi=300,\n",
    "                      figsize=(20, 4), show=True, filename=None, font_size=12):\n",
    "    \"\"\" Plots a scatter plot with abline of the estimated posterior means vs true values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta_true: np.array\n",
    "        Array of true parameters.\n",
    "    theta_est: np.array\n",
    "        Array of estimated parameters.\n",
    "    param_names: list\n",
    "        List of parameter names for plotting.\n",
    "    D : int\n",
    "        Number of dimensions of parameters.\n",
    "    dpi: int, default:300\n",
    "        Dots per inch (dpi) for the plot.\n",
    "    figsize: tuple(int, int), default: (20,4)\n",
    "        Figure size.\n",
    "    show: boolean, default: True\n",
    "        Controls if the plot will be shown\n",
    "    filename: str, default: None\n",
    "        Filename if plot shall be saved\n",
    "    font_size: int, default: 12\n",
    "        Font size\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = 0\n",
    "\n",
    "    # Plot settings\n",
    "    plt.rcParams['font.size'] = font_size\n",
    "\n",
    "    # Determine n_subplots dynamically\n",
    "    n_row = D+1\n",
    "    n_col = D\n",
    "\n",
    "    # Initialize figure\n",
    "    f, axarr = plt.subplots(n_row, n_col, figsize=figsize)\n",
    "        \n",
    "    # --- Plot true vs estimated posterior means on a single row --- #\n",
    "    \n",
    "    for i in range(n_row):\n",
    "        for j in range(n_col):\n",
    "            if j>(i-1) and i != 0:\n",
    "                axarr[i, j].axis('off')\n",
    "            else:\n",
    "                # Plot analytic vs estimated\n",
    "                axarr[i, j].scatter(theta_est[:, idx], theta_true[:, idx], color='black', alpha=0.4)\n",
    "\n",
    "                # get axis limits and set equal x and y limits\n",
    "                lower_lim = min(axarr[i, j].get_xlim()[0], axarr[i, j].get_ylim()[0])\n",
    "                upper_lim = max(axarr[i, j].get_xlim()[1], axarr[i, j].get_ylim()[1])\n",
    "                axarr[i, j].set_xlim((lower_lim, upper_lim))\n",
    "                axarr[i, j].set_ylim((lower_lim, upper_lim))\n",
    "                axarr[i, j].plot(axarr[i, j].get_xlim(), axarr[i, j].get_xlim(), '--', color='black')\n",
    "\n",
    "                # Compute NRMSE\n",
    "                rmse = np.sqrt(np.mean( (theta_est[:, idx] - theta_true[:, idx])**2 ))\n",
    "                nrmse = rmse / (theta_true[:, idx].max() - theta_true[:, idx].min())\n",
    "                axarr[i, j].text(0.1, 0.9, 'NRMSE={:.3f}'.format(nrmse),\n",
    "                             horizontalalignment='left',\n",
    "                             verticalalignment='center',\n",
    "                             transform=axarr[i, j].transAxes,\n",
    "                             size=10)\n",
    "\n",
    "                # Compute R2\n",
    "                #r2 = r2_score(theta_true[:, j], theta_est[:, j])\n",
    "                #axarr[j].text(0.1, 0.8, '$R^2$={:.3f}'.format(r2),\n",
    "                #             horizontalalignment='left',\n",
    "                #             verticalalignment='center',\n",
    "                #             transform=axarr[j].transAxes, \n",
    "                #             size=10)\n",
    "\n",
    "                if j == 0 and i == 0 or 0==0:\n",
    "                    # Label plot\n",
    "                    axarr[i, j].set_xlabel('Estimated')\n",
    "                    axarr[i, j].set_ylabel('True')\n",
    "                axarr[i, j].set_title(param_names[idx])\n",
    "                axarr[i, j].spines['right'].set_visible(False)\n",
    "                axarr[i, j].spines['top'].set_visible(False)\n",
    "                \n",
    "                idx += 1\n",
    "    \n",
    "    # Adjust spaces\n",
    "    f.tight_layout()\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if filename is not None:\n",
    "        f.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, x = generative_model(200, 100)\n",
    "param_samples = trainer.network.sample(x, n_samples=200)\n",
    "param_means = param_samples.mean(axis=0)\n",
    "\n",
    "theta = theta_cov_to_corr(theta, D=D)\n",
    "param_means = theta_cov_to_corr(param_means, D=D)\n",
    "\n",
    "param_names = ['mu_{}'.format(i) for i in range(1, D+1)] + \\\n",
    "['sd_{}'.format(i+1) if i==j else 'cor_{}{}'.format(i+1, j+1) for (i, j) in zip(*np.tril_indices(D))]\n",
    "\n",
    "# true parameters\n",
    "print(\"BayesFlow (x) vs. true thetas (y) -- Recovery of true thetas\")\n",
    "true_vs_estimated_tril(theta, param_means, param_names, D, figsize=(20,20))\n",
    "\n",
    "#print('\\n\\nSummary network response for one batch')\n",
    "#s = np.array(trainer.network.summary_net(x))\n",
    "#sns.pairplot(pd.DataFrame(s, columns=['s_{}'.format(i) for i in range(1, s.shape[1]+1)]), kind=\"kde\")\n",
    "\n",
    "#print('\\n\\nFull posterior for one dataset.')\n",
    "#p = param_samples[0]\n",
    "#sns.pairplot(pd.DataFrame(p, columns=['dim_{}'.format(i) for i in range(1, p.shape[1]+1)]), kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
