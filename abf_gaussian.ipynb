{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../BayesFlow')))\n",
    "\n",
    "from bayesflow.trainers import ParameterEstimationTrainer\n",
    "from bayesflow.networks import InvertibleNetwork, InvariantNetwork\n",
    "from bayesflow.amortizers import SingleModelAmortizer\n",
    "from bayesflow.models import GenerativeModel\n",
    "from bayesflow.diagnostics import true_vs_estimated\n",
    "from bayesflow.exceptions import ConfigurationError\n",
    "\n",
    "from meta_aux_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPrior:\n",
    "    def __init__(self, D, mu_mean=0, mu_scale=1):\n",
    "        self.D = D\n",
    "        self.mu_mean = mu_mean\n",
    "        self.mu_scale = mu_scale\n",
    "    \n",
    "    def __call__(self, n_sim):\n",
    "        theta = np.random.default_rng().normal(self.mu_mean, self.mu_scale, size=(n_sim, self.D))\n",
    "        return theta\n",
    "\n",
    "class GaussianSimulator:\n",
    "    def __init__(self, D, s = None):\n",
    "        \n",
    "        # Default: Unit variance\n",
    "        if s is None:\n",
    "            sigma = np.eye(D)\n",
    "            \n",
    "        # Unit variance with factor s\n",
    "        elif isinstance(s, (int, float)):\n",
    "            sigma = np.eye(D) * s\n",
    "            \n",
    "            \n",
    "        # s is list or np.array --> Either custom diagonal or full\n",
    "        elif isinstance(s, (list, np.ndarray)):\n",
    "            # cast any list-like input to float np.array \n",
    "            if isinstance(s, list):\n",
    "                s = np.array(s)   \n",
    "            s = s.astype(float)\n",
    "            \n",
    "            # Diagonal covariance matrix with different diagonal entries (from s)\n",
    "            if s.ndim == 1:\n",
    "                assert len(s) == D, \"Must provide D entries in diagonal s!\"\n",
    "                sigma = np.diag(s)\n",
    "                \n",
    "            # Full covariance matrix    \n",
    "            elif s.ndim == 2:\n",
    "                assert s.shape[0] == D and s.shape[1] == D, \"Must provide DxD matrix!\"\n",
    "                try: \n",
    "                    _ = np.linalg.cholesky(s)\n",
    "                except:\n",
    "                    raise ConfigurationError(\"Covariance Matrix must be positive semidefinite!\")\n",
    "                \n",
    "                sigma = s\n",
    "            \n",
    "        self.D = D    \n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def __call__(self, theta, n_obs):\n",
    "        n_sim, D = theta.shape\n",
    "        assert D == self.D\n",
    "        \n",
    "        tril = tf.linalg.cholesky(np.stack([self.sigma] * n_sim))   # tf requires cholesky decomposed sigma\n",
    "        \n",
    "        mvn = tfp.distributions.MultivariateNormalTriL(loc=theta, scale_tril=tril)\n",
    "\n",
    "        sim_data = mvn.sample(n_obs)\n",
    "        sim_data = np.array(sim_data)\n",
    "        sim_data = np.transpose(sim_data, (1, 0, 2))\n",
    "        return sim_data\n",
    "    \n",
    "D = 3\n",
    "prior = GaussianPrior(D=D)\n",
    "simulator = GaussianSimulator(D=D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "prior = GaussianPrior(D=D)\n",
    "simulator = GaussianSimulator(D=D, s = 2.5)\n",
    "\n",
    "theta = prior(4)\n",
    "print(simulator.sigma)\n",
    "simulator(theta, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "prior = GaussianPrior(D=D)\n",
    "simulator = GaussianSimulator(D=D, s = [1,2,3])\n",
    "\n",
    "theta = prior(4)\n",
    "print(simulator.sigma)\n",
    "simulator(theta, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "prior = GaussianPrior(D=D)\n",
    "simulator = GaussianSimulator(D=D, s = np.array([1,2,3]))\n",
    "\n",
    "theta = prior(4)\n",
    "print(simulator.sigma)\n",
    "simulator(theta, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "prior = GaussianPrior(D=D)\n",
    "simulator = GaussianSimulator(D=D, s = np.array([[1,0,0],[0,1,0],[0,0,1]]))\n",
    "\n",
    "theta = prior(4)\n",
    "print(simulator.sigma)\n",
    "simulator(theta, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5 \n",
    "\n",
    "#########\n",
    "\n",
    "prior = GaussianPrior(D=D)\n",
    "simulator = GaussianSimulator(D=D)\n",
    "generative_model = GenerativeModel(prior, simulator)\n",
    "\n",
    "#########\n",
    "\n",
    "summary_meta = {\n",
    "    'n_dense_s1': 2,\n",
    "    'n_dense_s2': 2,\n",
    "    'n_dense_s3': 2,\n",
    "    'n_equiv':    1,\n",
    "    'dense_s1_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s2_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s3_args': {'activation': 'relu', 'units': 32},\n",
    "}\n",
    "\n",
    "class BottleneckSummaryNet(tf.keras.Model):\n",
    "    def __init__(self, inv_meta={}, n_out=10, activation_out=None):\n",
    "        super(BottleneckSummaryNet, self).__init__()\n",
    "\n",
    "        self.invariant_net = InvariantNetwork(inv_meta)\n",
    "        self.out_layer = tf.keras.layers.Dense(n_out, activation=activation_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out_inv = self.invariant_net(x)\n",
    "        out = self.out_layer(out_inv)\n",
    "        return out\n",
    "\n",
    "\n",
    "summary_net = BottleneckSummaryNet(inv_meta=summary_meta, \n",
    "                                   n_out=D*2,  # one mean and variance per dim\n",
    "                                   activation_out=None  # linear\n",
    "                                  )\n",
    "\n",
    "\n",
    "inference_meta = {\n",
    "    'n_coupling_layers': 2,\n",
    "    's_args': {\n",
    "        'units': [32, 32, 32],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [32, 32, 32],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'n_params': D,\n",
    "    'alpha': 1.9,\n",
    "    'permute': True\n",
    "}\n",
    "\n",
    "inference_net = InvertibleNetwork({'n_params': D})\n",
    "\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ParameterEstimationTrainer(amortizer,\n",
    "                      generative_model,\n",
    "                      learning_rate=0.0001,\n",
    "                      checkpoint_path='ckpt/'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = trainer.train_online(epochs=1, iterations_per_epoch=100, batch_size=512, n_obs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = trainer.train_rounds(epochs=10, rounds=5, sim_per_round=20000, batch_size=512, n_obs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate (quick and dirty)\n",
    "p, x = trainer._forward_inference(200, 100)\n",
    "param_samples = trainer.network.sample(x, n_samples=200)\n",
    "param_means = param_samples.mean(axis=0)\n",
    "true_vs_estimated(p, param_means, ['mu{}'.format(i) for i in range(1, 5+1)], figsize=(20,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.network.summary_net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
